{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26655b1b-6d28-4830-8fb0-911ab6b14bf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Random Forest Notebook\n",
    "Attempting to implement random forrest algorithm for research and performance\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "https://data36.com/random-forest-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ad5c5-254c-4dff-bdbb-e6a4d6f34d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Some info from good ol' ChatGPT\n",
    "Random Forest is an ensemble learning method that uses multiple decision trees to make predictions. Here's how it works:\n",
    "\n",
    "    Building the trees: Random Forest constructs a set of decision trees, each of which is trained on a random subset of the input features and a random subset of the data points. The tree is grown by recursively splitting the data into subsets based on the values of the input features.\n",
    "\n",
    "    Making predictions: To make a prediction for a new data point, Random Forest takes the average of the predictions of all the trees in the forest. Each tree produces a prediction based on the input features and the subset of data it was trained on.\n",
    "\n",
    "    Handling missing data: Random Forest can handle missing data in the input features by using surrogate splits. If a data point is missing a value for a particular feature, the algorithm can use a different feature that is highly correlated with the missing feature to make a split in the decision tree.\n",
    "\n",
    "    Handling imbalanced data: Random Forest can also handle imbalanced data by using class weights or resampling techniques to ensure that each class is represented in the training data.\n",
    "\n",
    "Random Forest has several advantages over other machine learning algorithms. It is robust to noise and missing data, can handle both continuous and categorical input features, and can be used for both regression and classification problems. However, there are some things to be aware of when using Random Forest:\n",
    "\n",
    "    Interpretability: Random Forest can be difficult to interpret, as the resulting model is a combination of many individual decision trees. It can be hard to understand which input features are most important for making predictions.\n",
    "\n",
    "    Overfitting: Random Forest can be prone to overfitting if the trees are too deep or if the number of trees in the forest is too high. Regularization techniques, such as limiting the depth of the trees or using a smaller number of trees, can help prevent overfitting.\n",
    "\n",
    "    Computationally expensive: Random Forest can be computationally expensive to train and evaluate, especially for large datasets with many input features. It is important to use efficient algorithms and data structures to reduce the training time and memory usage.\n",
    "\n",
    "Overall, Random Forest is a powerful and versatile algorithm that can be effective for many machine learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9ef8e-5157-4d1c-9681-bfa6d522ef8c",
   "metadata": {},
   "source": [
    "### Todo:\n",
    "Understand and improve RF Model\n",
    "Implement vectorisation model\n",
    "Abstract data processing and filtering/wrangling to function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88c24cc-7b23-4390-a06b-b1c84ce63c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428d4c4f-c793-4a55-b17c-1838ef80e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes warnings for the error messege\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Make sparse coulms, fix everything\n",
    "# Scale the data for svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33249f00-7cd2-4c87-96d1-c1e9eff24bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_full_train = pd.read_csv(r\"book_rating_train.csv\", index_col = False, delimiter = ',', header=0)\n",
    "X_train = X_full_train.iloc[:,:-1]\n",
    "Y_train = X_full_train[\"rating_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fc60e3-cb9d-4edf-b001-ad4a879ce2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_data_source = \"book_text_features_doc2vec\"\n",
    "# Maybe replace names of 0, 1, 2 etc with word vector i\n",
    "# can't do random forrest with float64, need int64\n",
    "authors_d2v_test = pd.read_csv(f\"{doc2vec_data_source}/test_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "authors_d2v_train = pd.read_csv(f\"{doc2vec_data_source}/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "desc_d2v_test = pd.read_csv(f\"{doc2vec_data_source}/test_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "desc_d2v_train = pd.read_csv(f\"{doc2vec_data_source}/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "name_d2v_test = pd.read_csv(f\"{doc2vec_data_source}/test_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "name_d2v_train = pd.read_csv(f\"{doc2vec_data_source}/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6134cf8-cdac-4114-89cf-15217530247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the data types, and removes all int data types\n",
    "# X_string = X.select_dtypes(exclude=\"number\")\n",
    "X_train_numerical = X_train.select_dtypes(include=\"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25e4e53-3315-4b99-a5b3-44df7bb43aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomForest(x_train=None, x_test=None, y_train=None, y_test=None, num_trees=100, depth=2, state=0):\n",
    "    clf = rfc(n_estimators=num_trees, max_depth=depth, random_state=state)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(x_test)\n",
    "    print(predictions)\n",
    "\n",
    "    describe_data = pd.DataFrame(predictions)\n",
    "    print(describe_data.describe())\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    # print(accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec97c48-7597-4d77-96a9-6332903f78ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_concat_train, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# acc_metrics = pd.DataFrame()\n",
    "\n",
    "# for trees in range(0,400,20):\n",
    "#     temp_acc_arr = []\n",
    "#     for depth in range(0, 10, 2):\n",
    "#         temp_acc_arr.append(randomForest(X_train, X_test, y_train, y_test, trees+1, depth+1))\n",
    "#     temp_df = pd.DataFrame(temp_acc_arr, columns=[str(trees)])\n",
    "#     acc_metrics = pd.concat([acc_metrics, temp_df], axis=1)\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"Time taken to run: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "# acc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7781c8c0-aaaa-40a9-b825-f919a3cab36d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run: 0.0238 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>PublishMonth</th>\n",
       "      <th>PublishDay</th>\n",
       "      <th>pagesNumber</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.096944</td>\n",
       "      <td>0.021326</td>\n",
       "      <td>0.304888</td>\n",
       "      <td>-0.084434</td>\n",
       "      <td>-0.138658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172811</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>-0.062941</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>-0.065377</td>\n",
       "      <td>0.227973</td>\n",
       "      <td>0.218879</td>\n",
       "      <td>-0.151266</td>\n",
       "      <td>-0.048105</td>\n",
       "      <td>0.300822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.074845</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.132891</td>\n",
       "      <td>0.051957</td>\n",
       "      <td>0.127083</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245650</td>\n",
       "      <td>-0.049657</td>\n",
       "      <td>0.072740</td>\n",
       "      <td>-0.055925</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.067133</td>\n",
       "      <td>-0.238091</td>\n",
       "      <td>0.109774</td>\n",
       "      <td>-0.156772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.127589</td>\n",
       "      <td>-0.100911</td>\n",
       "      <td>0.158580</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>-0.065661</td>\n",
       "      <td>-0.037972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033781</td>\n",
       "      <td>0.093943</td>\n",
       "      <td>0.132654</td>\n",
       "      <td>0.030295</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.154334</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>-0.231493</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>-0.098540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>-0.048197</td>\n",
       "      <td>0.106046</td>\n",
       "      <td>-0.100795</td>\n",
       "      <td>-0.147681</td>\n",
       "      <td>-0.017288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>-0.149720</td>\n",
       "      <td>0.150557</td>\n",
       "      <td>0.294355</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.049340</td>\n",
       "      <td>-0.037548</td>\n",
       "      <td>0.042920</td>\n",
       "      <td>0.176173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>352</td>\n",
       "      <td>-0.162106</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>0.189444</td>\n",
       "      <td>-0.042658</td>\n",
       "      <td>-0.117135</td>\n",
       "      <td>-0.075968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0.044182</td>\n",
       "      <td>0.054631</td>\n",
       "      <td>-0.025782</td>\n",
       "      <td>0.049917</td>\n",
       "      <td>0.122052</td>\n",
       "      <td>-0.084216</td>\n",
       "      <td>-0.096424</td>\n",
       "      <td>-0.068681</td>\n",
       "      <td>-0.005293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>1997</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>-0.194677</td>\n",
       "      <td>0.063026</td>\n",
       "      <td>0.125115</td>\n",
       "      <td>-0.041354</td>\n",
       "      <td>-0.122502</td>\n",
       "      <td>-0.207333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.062899</td>\n",
       "      <td>0.048064</td>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.191065</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>-0.100516</td>\n",
       "      <td>-0.190299</td>\n",
       "      <td>0.224559</td>\n",
       "      <td>0.086601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059</th>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.115993</td>\n",
       "      <td>-0.003955</td>\n",
       "      <td>-0.027285</td>\n",
       "      <td>-0.032830</td>\n",
       "      <td>0.091905</td>\n",
       "      <td>-0.257285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150964</td>\n",
       "      <td>-0.029046</td>\n",
       "      <td>0.171029</td>\n",
       "      <td>-0.072123</td>\n",
       "      <td>-0.004459</td>\n",
       "      <td>0.247430</td>\n",
       "      <td>0.111973</td>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.070569</td>\n",
       "      <td>-0.112066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23060</th>\n",
       "      <td>1989</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>-0.126878</td>\n",
       "      <td>-0.120418</td>\n",
       "      <td>0.198828</td>\n",
       "      <td>0.093403</td>\n",
       "      <td>-0.053232</td>\n",
       "      <td>-0.114909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193755</td>\n",
       "      <td>-0.118570</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>-0.108623</td>\n",
       "      <td>-0.036143</td>\n",
       "      <td>0.168113</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>0.087885</td>\n",
       "      <td>0.113180</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061</th>\n",
       "      <td>1998</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>-0.134530</td>\n",
       "      <td>-0.061256</td>\n",
       "      <td>0.178935</td>\n",
       "      <td>0.057537</td>\n",
       "      <td>-0.045066</td>\n",
       "      <td>-0.088796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.154127</td>\n",
       "      <td>0.219128</td>\n",
       "      <td>-0.305824</td>\n",
       "      <td>-0.017904</td>\n",
       "      <td>-0.059886</td>\n",
       "      <td>0.108616</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>-0.138893</td>\n",
       "      <td>-0.044187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062</th>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>-0.204117</td>\n",
       "      <td>-0.007189</td>\n",
       "      <td>0.375681</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>-0.341423</td>\n",
       "      <td>-0.061017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068714</td>\n",
       "      <td>-0.065924</td>\n",
       "      <td>0.082228</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.099006</td>\n",
       "      <td>0.081608</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>-0.048776</td>\n",
       "      <td>0.032433</td>\n",
       "      <td>0.132977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23063 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PublishYear  PublishMonth  PublishDay  pagesNumber         0         1  \\\n",
       "0             2005             6           1           48  0.359375 -0.096944   \n",
       "1             1991            10           1          364 -0.074845  0.060063   \n",
       "2             2005             3          31           32 -0.127589 -0.100911   \n",
       "3             2004             9           1          293 -0.000472 -0.048197   \n",
       "4             2005             7           7          352 -0.162106 -0.023212   \n",
       "...            ...           ...         ...          ...       ...       ...   \n",
       "23058         1997             8           1          120 -0.194677  0.063026   \n",
       "23059         2005             6           1           32 -0.115993 -0.003955   \n",
       "23060         1989             2          15          132 -0.126878 -0.120418   \n",
       "23061         1998             4          21          136 -0.134530 -0.061256   \n",
       "23062         2002             7           8          192 -0.204117 -0.007189   \n",
       "\n",
       "              2         3         4         5  ...        90        91  \\\n",
       "0      0.021326  0.304888 -0.084434 -0.138658  ... -0.172811  0.098389   \n",
       "1      0.132891  0.051957  0.127083  0.017997  ...  0.245650 -0.049657   \n",
       "2      0.158580  0.046532 -0.065661 -0.037972  ... -0.033781  0.093943   \n",
       "3      0.106046 -0.100795 -0.147681 -0.017288  ...  0.020762 -0.149720   \n",
       "4      0.189444 -0.042658 -0.117135 -0.075968  ...  0.191644  0.044182   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23058  0.125115 -0.041354 -0.122502 -0.207333  ... -0.000418 -0.062899   \n",
       "23059 -0.027285 -0.032830  0.091905 -0.257285  ...  0.150964 -0.029046   \n",
       "23060  0.198828  0.093403 -0.053232 -0.114909  ...  0.193755 -0.118570   \n",
       "23061  0.178935  0.057537 -0.045066 -0.088796  ...  0.009007  0.154127   \n",
       "23062  0.375681  0.011292 -0.341423 -0.061017  ...  0.068714 -0.065924   \n",
       "\n",
       "             92        93        94        95        96        97        98  \\\n",
       "0     -0.062941  0.118057 -0.065377  0.227973  0.218879 -0.151266 -0.048105   \n",
       "1      0.072740 -0.055925 -0.000046  0.140500  0.067133 -0.238091  0.109774   \n",
       "2      0.132654  0.030295  0.102714  0.154334  0.129325 -0.231493  0.007541   \n",
       "3      0.150557  0.294355  0.001157  0.285179  0.049340 -0.037548  0.042920   \n",
       "4      0.054631 -0.025782  0.049917  0.122052 -0.084216 -0.096424 -0.068681   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23058  0.048064  0.029612  0.191065  0.096081 -0.100516 -0.190299  0.224559   \n",
       "23059  0.171029 -0.072123 -0.004459  0.247430  0.111973  0.019573  0.070569   \n",
       "23060  0.006740 -0.108623 -0.036143  0.168113  0.136478  0.087885  0.113180   \n",
       "23061  0.219128 -0.305824 -0.017904 -0.059886  0.108616  0.041879 -0.138893   \n",
       "23062  0.082228 -0.003849  0.099006  0.081608  0.094459 -0.048776  0.032433   \n",
       "\n",
       "             99  \n",
       "0      0.300822  \n",
       "1     -0.156772  \n",
       "2     -0.098540  \n",
       "3      0.176173  \n",
       "4     -0.005293  \n",
       "...         ...  \n",
       "23058  0.086601  \n",
       "23059 -0.112066  \n",
       "23060  0.000569  \n",
       "23061 -0.044187  \n",
       "23062  0.132977  \n",
       "\n",
       "[23063 rows x 224 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging all data together\n",
    "# doc2vec\n",
    "start_time = time.time()\n",
    "\n",
    "X_train_merged = pd.concat([X_train_numerical, authors_d2v_train, desc_d2v_train, name_d2v_train], axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to run: {elapsed_time:.4f} seconds\")\n",
    "X_train_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c41c01-707a-48bf-8ed6-5ce8a0f5db96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# x_nan_removed = X.dropna()\n",
    "# Big flaw I made is dropping rows, need to remove respective nan ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b7b272-ff2d-4021-a7a1-44285fd9f49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23063, 4), (23063, 20), (23063, 100), (23063, 100))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_numerical.shape, authors_d2v_train.shape, desc_d2v_train.shape, name_d2v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f966c4-edd9-4a13-b706-2dd9ccb1ba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. ... 4. 4. 4.]\n",
      "            0\n",
      "count  4613.0\n",
      "mean      4.0\n",
      "std       0.0\n",
      "min       4.0\n",
      "25%       4.0\n",
      "50%       4.0\n",
      "75%       4.0\n",
      "max       4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7112508129200087"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_merged, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "randomForest(X_train, X_test, y_train, y_test, 100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57628251-7dbc-495e-a38b-bcd625f67c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pd.read_csv(r\"book_rating_test.csv\", index_col = False, delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6272b4b0-d818-4969-87ab-d6fc851d5358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027706716385552"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16208 / Y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f99977-fa5c-42e5-9cf5-52061f9a0651",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame._add_numeric_operations.<locals>.max of     Unnamed: 0         0        20        40        60        80       100  \\\n",
       "0            0  0.708790  0.708790  0.708790  0.708790  0.708790  0.708790   \n",
       "1            1  0.708790  0.708790  0.708790  0.708790  0.708790  0.708790   \n",
       "2            2  0.708790  0.708790  0.708790  0.708790  0.708790  0.708790   \n",
       "3            3  0.706842  0.708790  0.708790  0.708790  0.708790  0.708790   \n",
       "4            4  0.705138  0.708790  0.708790  0.708790  0.708790  0.708790   \n",
       "5            5  0.696616  0.708790  0.708790  0.708546  0.708790  0.708546   \n",
       "6            6  0.698807  0.708546  0.708790  0.708790  0.708790  0.708546   \n",
       "7            7  0.690772  0.708546  0.708790  0.708546  0.708790  0.708790   \n",
       "8            8  0.682737  0.708790  0.708790  0.709277  0.709277  0.709033   \n",
       "9            9  0.675676  0.710251  0.709033  0.710007  0.709277  0.709520   \n",
       "10          10  0.671049  0.708546  0.709520  0.709520  0.710251  0.710251   \n",
       "11          11  0.668858  0.710251  0.710251  0.710494  0.710494  0.710251   \n",
       "12          12  0.634039  0.708059  0.710007  0.709520  0.710007  0.710494   \n",
       "13          13  0.637205  0.711955  0.711712  0.712199  0.711225  0.711712   \n",
       "14          14  0.657171  0.708059  0.711225  0.710494  0.710738  0.711712   \n",
       "15          15  0.631118  0.707085  0.707816  0.710494  0.711468  0.710981   \n",
       "16          16  0.627952  0.708790  0.709033  0.710738  0.710981  0.711468   \n",
       "17          17  0.591429  0.710494  0.709764  0.710494  0.710981  0.711712   \n",
       "18          18  0.597516  0.709277  0.711468  0.709520  0.711955  0.713660   \n",
       "19          19  0.594351  0.712199  0.712199  0.710007  0.712686  0.712199   \n",
       "\n",
       "         120       140       160  ...       800       820       840       860  \\\n",
       "0   0.708790  0.708790  0.708790  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "1   0.708790  0.708790  0.708790  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "2   0.708790  0.708790  0.708790  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "3   0.708790  0.708790  0.708790  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "4   0.708790  0.708790  0.708790  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "5   0.708546  0.708546  0.708546  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "6   0.708546  0.708546  0.708546  ...  0.708546  0.708546  0.708546  0.708546   \n",
       "7   0.708790  0.708790  0.708790  ...  0.708790  0.708790  0.708790  0.708790   \n",
       "8   0.709033  0.709277  0.709277  ...  0.709033  0.709033  0.709033  0.709033   \n",
       "9   0.709277  0.709277  0.709277  ...  0.709520  0.709520  0.709520  0.709520   \n",
       "10  0.710007  0.709764  0.710007  ...  0.710007  0.710007  0.710007  0.710007   \n",
       "11  0.710251  0.710494  0.710494  ...  0.710251  0.710251  0.710251  0.710251   \n",
       "12  0.710007  0.709520  0.709764  ...  0.710007  0.709764  0.710007  0.710007   \n",
       "13  0.711712  0.711225  0.710981  ...  0.710494  0.710981  0.710981  0.710738   \n",
       "14  0.711468  0.710981  0.711468  ...  0.711225  0.710981  0.710981  0.710981   \n",
       "15  0.711712  0.711468  0.711955  ...  0.711225  0.710981  0.710981  0.710738   \n",
       "16  0.711225  0.712199  0.711468  ...  0.711225  0.711225  0.710981  0.711225   \n",
       "17  0.714390  0.713903  0.713173  ...  0.711955  0.711955  0.711955  0.711955   \n",
       "18  0.712929  0.713173  0.712929  ...  0.710981  0.711225  0.710981  0.710981   \n",
       "19  0.711955  0.712929  0.713416  ...  0.711225  0.710738  0.710251  0.710738   \n",
       "\n",
       "         880       900       920       940       960       980  \n",
       "0   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "1   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "2   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "3   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "4   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "5   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "6   0.708546  0.708546  0.708546  0.708546  0.708546  0.708546  \n",
       "7   0.708790  0.708790  0.708790  0.708790  0.708790  0.708790  \n",
       "8   0.709033  0.709033  0.709033  0.709033  0.709033  0.709033  \n",
       "9   0.709277  0.709520  0.709520  0.709520  0.709520  0.709520  \n",
       "10  0.710007  0.710007  0.710007  0.710007  0.710007  0.710007  \n",
       "11  0.710251  0.710251  0.710251  0.710251  0.710251  0.710251  \n",
       "12  0.710007  0.709764  0.710007  0.710007  0.710251  0.710251  \n",
       "13  0.710738  0.710738  0.710494  0.710981  0.710494  0.710251  \n",
       "14  0.711225  0.710981  0.710981  0.711225  0.711225  0.710981  \n",
       "15  0.710981  0.710981  0.710738  0.711225  0.711225  0.711225  \n",
       "16  0.711225  0.711468  0.710981  0.710981  0.711225  0.711225  \n",
       "17  0.712199  0.711955  0.711955  0.711955  0.711712  0.711712  \n",
       "18  0.711468  0.711225  0.710981  0.710738  0.710981  0.710981  \n",
       "19  0.710738  0.710738  0.710738  0.711225  0.710981  0.710981  \n",
       "\n",
       "[20 rows x 51 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data = pd.read_csv(r\"RF_accuracy_scores.csv\", index_col = False, delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d405d94e-07c3-4eaa-9ecf-32cf837b9b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bf89e-35e7-4eba-9f36-234981c7f1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
